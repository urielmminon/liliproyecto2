{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final - Métodos de Gran Escala\n",
    "Equipo 1:\n",
    "- Itzel Muñoz: 122803\n",
    "- Uriel Miranda: 177508\n",
    "- Luis Puente: 103108\n",
    "- Juan Martínez Parente: 124458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La configuración y lectura de datos en _H2O_ fue sobre una base ya filtrada, contiene solamente medicamentos del Distrito Federal de abril 2016, con las columnas `dia`, `municipio`, `latitud`, `longitud`, `cadenacomercial`, `producto` y`precio`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/lectura8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con H2O genera 1 modelo ocupando un GridSearch con al menos 2 hiperparámetros y 3 valores diferentes para cada hiperparámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el _grid search_ decidimos hacer un modelos de _distributed random forests_. Después de filtrar para la categoría de medicamentos, para el Distrito Federal y para el mes de abril de 2016, modelamos `precio` en términos de `dia`, `municipio`, `latitud`, `longitud`, `cadenacomercial` y `producto`. Los hiperparámetros fueron:\n",
    "- `ntrees` para los valores 64, 96 y 128. En este [_paper_ de 2012](https://www.researchgate.net/publication/230766603_How_Many_Trees_in_a_Random_Forest) de Mayumi, Santoro y Baranauskas se sugiere probar este parámetro en el intervalo [64, 128].\n",
    "- `max_depth` para los valores 2, 5 y 7. 2 es la profundidad mínima, y como contamos con seis variables explicativas, una profundidad máxima de 7 nos pareció razonable.\n",
    "- `min_rows` para los valores 1, 50 y 100. El primero es el valor por defecto, que suele ser bueno para modelos de bosques aleatorios, ya que es buena idea \"dejar crecer\" los árboles lo más posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/scr1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/scr2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo que tardó en correr el _grid search_ fue de 2 minutos con 47 segundos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/scr3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las 27 combinaciones posibles de los hiperparámetros, el mejor modelo fue el de los valores `max_depth = 7`, `min_rows = 1` y `ntrees = 96`, con una devianza de residuales de casi la mitad del tamaño de la devianza del peor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/scr4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo presenta un buen ajuste: una R cuadrada del 85% para entrenamiento y 86% para validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/scr5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/scr6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la última tabla vemos que `producto` fue, por mucho, la variable más importante; representa el 98.84% de la importancia. Pese a que el resto de las variables tiene importancias muy pequeñas, creemos que esto hace sentido, ya que el producto en sí mismo es el mejor indicador de su precio (entre las variables disponibles), más que la cadena, la fecha, o la ubicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con H2O realiza un AutoML para encontrar el mejor modelo que prediga el precio. Local en una máquina. Selecciona al menos 3 modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la misma base descrita previamente, es decir, filtrada para tener solamente medicamentos del Distrito Federal de abril 2016 y tomando como variables explicativas `dia`, `municipio`, `latitud`, `longitud`, `cadenacomercial` y `producto` para modelar el `precio`, realizamos _AutoML_ con 3 modelos diferentes:\n",
    "- `Generalized Linear Model`\n",
    "- `Distributed Random Forest`\n",
    "- `Gradient Boosting Machine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La configuración del _AutoML_ se muestra en las siguientes imágenes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo que tomó ejecutar _AutoML_ fue de casi 12 minutos, como se muestra en la imagen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_AutoML_ ejecutó 180 modelos, siendo el ganador `Gradient Boosting Machine` con una devianza de 15,327.60:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros del modelo ganador fueron 40 árboles, con profundidad máxima de 12 y un mínimo de observación por nodo de 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo presenta un buen desempeño, con una R 90.17% en validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente la variable más importante (mucho más importante que el resto) es `producto`, en este caso con el 95% del peso de las variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, las características del modelo son las siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/auto10.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
