{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import findspark\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(os.environ['SPARK_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyspark \n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.sql.functions import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la sesión de spark\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".appName(\"spark_Parte2\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profecoSchema = StructType([StructField(\"producto\", StringType(), True), \\\n",
    "                     StructField(\"presentacion\", StringType(), True), \\\n",
    "                     StructField(\"marca\", StringType(), True), \\\n",
    "                     StructField(\"categoria\", StringType(), True), \\\n",
    "                     StructField(\"catalogo\", StringType(), True), \\\n",
    "                     StructField(\"precio\", DoubleType(), True), \\\n",
    "                     StructField(\"fecharegistro\", TimestampType(), True), \\\n",
    "                     StructField(\"cadenacomercial\", StringType(), True), \\\n",
    "                     StructField(\"giro\", StringType(), True), \\\n",
    "                     StructField(\"nombrecomercial\", StringType(), True), \\\n",
    "                     StructField(\"direccion\", StringType(), True), \\\n",
    "                     StructField(\"estado\", StringType(), True), \\\n",
    "                     StructField(\"municipio\", StringType(), True), \\\n",
    "                     StructField(\"latitud\", DoubleType(), True), \\\n",
    "                     StructField(\"longitud\", DoubleType(), True)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profecoDf = spark.read.format(\"csv\")\\\n",
    "        .option(\"delimiter\", \"|\")\\\n",
    "        .option(\"header\",\"true\")\\\n",
    "        .schema(profecoSchema) \\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load(\"profeco_final_bash.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "profecoDF = spark.read.format('parquet')\\\n",
    "        .load(\"profecoFinal.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- producto: string (nullable = true)\n",
      " |-- presentacion: string (nullable = true)\n",
      " |-- marca: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- catalogo: string (nullable = true)\n",
      " |-- precio: double (nullable = true)\n",
      " |-- fecharegistro: timestamp (nullable = true)\n",
      " |-- cadenacomercial: string (nullable = true)\n",
      " |-- giro: string (nullable = true)\n",
      " |-- nombrecomercial: string (nullable = true)\n",
      " |-- direccion: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- latitud: double (nullable = true)\n",
      " |-- longitud: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profecoDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación de variables\n",
    "sqlTrans = SQLTransformer( \\\n",
    "    statement=\"SELECT *,DAY(fecharegistro) AS dia FROM  __THIS__ \\\n",
    "          WHERE categoria LIKE '%medicamentos%' \\\n",
    "          AND estado='distrito federal' \\\n",
    "          AND MONTH(fecharegistro)=4 \\\n",
    "          AND YEAR(fecharegistro)=2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de label / predictor\n",
    "#assemblerPrecio = VectorAssembler(inputCols=[\"precio\"],outputCol=\"precioVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de variables\n",
    "#scalerPrecio = Normalizer(inputCol='precioVec', outputCol='scaled_precio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables\n",
    "formula = SQLTransformer( \\\n",
    "    statement=\"SELECT producto, marca, precio, dia ,cadenacomercial, municipio , latitud,longitud FROM  __THIS__ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de String a categótico\n",
    "productoIndexer = StringIndexer(inputCol=\"producto\", outputCol=\"productoIndex\")\n",
    "marcaIndexer = StringIndexer(inputCol=\"marca\", outputCol=\"marcaIndex\")\n",
    "cadenacomercialIndexer = StringIndexer(inputCol=\"cadenacomercial\", outputCol=\"cadenacomercialIndex\")\n",
    "municipioIndexer = StringIndexer(inputCol=\"municipio\", outputCol=\"municipioIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"productoIndex\", \"marcaIndex\", \"dia\",\"cadenacomercialIndex\",\"municipioIndex\",\"latitud\",\"longitud\"],\n",
    "    outputCol=\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest model\n",
    "rf = RandomForestRegressor(labelCol='precio',featuresCol='Features',maxBins=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[sqlTrans,formula,productoIndexer,marcaIndexer,cadenacomercialIndexer,municipioIndexer,assembler,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fit\n",
    "model = pipeline.fit(profecoDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.transform(profecoDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|precio|        prediction|\n",
      "+------+------------------+\n",
      "|1203.9| 993.4524419686411|\n",
      "|179.68|166.25676723535088|\n",
      "|111.55|158.21065861855678|\n",
      "|1008.9| 993.4524419686411|\n",
      "|  80.7|129.40895074936634|\n",
      "+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"precio\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 166.484\n",
      "SQLTransformer_e9dabaa24c40\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"precio\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(prediction)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rfModel = model.stages[1]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
